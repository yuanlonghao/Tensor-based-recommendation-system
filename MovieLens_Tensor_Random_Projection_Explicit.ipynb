{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing the performance of Tensor Random Projection on Recommendation System\n",
    "from tr_functions import *\n",
    "import timeit\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data is of size (610, 9724, 23) and contains 100836 ratings.\n"
     ]
    }
   ],
   "source": [
    "# MovieLens Latest Datasets: https://grouplens.org/datasets/movielens/\n",
    "# users: 610, movies: 9743\n",
    "ratings = pd.read_csv(r'C:\\Users\\LHY\\Dropbox\\Gunosy\\Jupyter\\data\\ml-edu\\ratings.csv')\n",
    "# time_stamp = np.array(ratings['timestamp'])\n",
    "# time_gap = (time_stamp.max()-time_stamp.min())/365/24/3600\n",
    "#print('The time gap of the data is', time_gap, 'years.')\n",
    "#print(ratings.dtypes)\n",
    "ratings.userId = ratings.userId.astype('category')\n",
    "ratings.movieId = ratings.movieId.astype('category')\n",
    "ratings.timestamp = ratings.timestamp.astype('category')\n",
    "#print(ratings.dtypes)\n",
    "\n",
    "ratings['userIndex'] = ratings.userId.cat.codes\n",
    "ratings['movieIndex'] = ratings.movieId.cat.codes\n",
    "ratings['timeIndex'] = ratings.timestamp.cat.codes\n",
    "ratings.sort_values(\"timeIndex\", inplace=True, ascending=True)\n",
    "#print(ratings.shape)\n",
    "#ratings.head()\n",
    "#ratings['time']\n",
    "\n",
    "#print('Number of users:', ratings['userIndex'].max())\n",
    "#print('Number of movies:', ratings['movieIndex'].max())\n",
    "#print('Number of timelines:', ratings['timeIndex'].max())\n",
    "rating_tensor = np.zeros((ratings['userIndex'].max()+1, ratings['movieIndex'].max()+1, 23))\n",
    "#print('Divide the ratings in 22 years')\n",
    "#print('The shape of the tensor data is', rating_tensor.shape)\n",
    "seq = ratings['timeIndex'].max()//22\n",
    "k = 1\n",
    "for i in range(100836):\n",
    "    if ratings['timeIndex'][i]//seq ==k:\n",
    "        k += 1\n",
    "        # print(ratings['timeIndex'][i], k)\n",
    "    rating_tensor[ratings['userIndex'][i], ratings['movieIndex'][i], k-1] = ratings['rating'][i]\n",
    "    \n",
    "\n",
    "data = np.copy(rating_tensor)\n",
    "data[data > 0] = 1\n",
    "print('The training data is of size', rating_tensor.shape, 'and contains', int(data.sum()), 'ratings.')\n",
    "#print('The tensor structure is user * movies * year of size 610 * 9724 * 23.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80668, 3) (20168, 3) (80668,) (20168,)\n",
      "The training/test tensor data is of size (610, 9724, 23) and contains 80668 / 20168 ratings.\n",
      "The training/test matrix data is of size (610, 9724) and contains 80668 / 20168 ratings.\n"
     ]
    }
   ],
   "source": [
    "# Train test split to test the generalization on test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(ratings[['userIndex', 'movieIndex', 'timeIndex']].values, \n",
    "                                                    ratings['rating'].values, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# formulate training tensor\n",
    "rating_tensor_train = np.zeros((ratings['userIndex'].max()+1, ratings['movieIndex'].max()+1, 23))\n",
    "seq = ratings['timeIndex'].max()//22\n",
    "for i in range(X_train.shape[0]):\n",
    "    rating_tensor_train[X_train[i, 0], X_train[i, 1], X_train[i, 2]//seq] = y_train[i]\n",
    "    \n",
    "# formulate test tensor\n",
    "rating_tensor_test = np.zeros((ratings['userIndex'].max()+1, ratings['movieIndex'].max()+1, 23))\n",
    "\n",
    "seq = ratings['timeIndex'].max()//22\n",
    "for i in range(X_test.shape[0]):\n",
    "    rating_tensor_test[X_test[i, 0], X_test[i, 1], X_test[i, 2]//seq] = y_test[i]\n",
    "    \n",
    "# formulate training matrix\n",
    "rating_matrix_train = np.zeros((ratings['userIndex'].max()+1, ratings['movieIndex'].max()+1))\n",
    "for i in range(X_train.shape[0]):\n",
    "    rating_matrix_train[X_train[i, 0], X_train[i, 1]] = y_train[i]\n",
    "    \n",
    "# formulate test matrix\n",
    "rating_matrix_test = np.zeros((ratings['userIndex'].max()+1, ratings['movieIndex'].max()+1))\n",
    "for i in range(X_test.shape[0]):\n",
    "    rating_matrix_test[X_test[i, 0], X_test[i, 1]] = y_test[i]\n",
    "\n",
    "\n",
    "data1 = np.copy(rating_tensor_train)\n",
    "data1[data1 > 0] = 1\n",
    "data2 = np.copy(rating_tensor_test)\n",
    "data2[data2 > 0] = 1\n",
    "print('The training/test tensor data is of size', rating_tensor_train.shape, 'and contains', int(data1.sum()),'/',int(data2.sum()), 'ratings.')\n",
    "print('The training/test matrix data is of size', rating_matrix_train.shape, 'and contains', int(data1.sum()),'/',int(data2.sum()), 'ratings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input mean\n",
    "user_ratings_mean = rating_tensor_train[rating_tensor_train>0].mean()\n",
    "rating_tensor_train_addmean = rating_tensor_train.copy()\n",
    "rating_tensor_train_addmean[rating_tensor_train_addmean==0] = user_ratings_mean\n",
    "\n",
    "rating_matrix_train_addmean = rating_matrix_train.copy()\n",
    "rating_matrix_train_addmean[rating_matrix_train_addmean==0] = user_ratings_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converging TR-ALS\n",
      "..........Finished!\n",
      "Converging TR-ALS\n",
      "..........Finished!\n",
      "Converging TR-ALS\n",
      "..........Finished!\n"
     ]
    }
   ],
   "source": [
    "# Train on the training data\n",
    "\n",
    "\n",
    "sampled_tensor = rating_tensor_train_addmean[0:500, 0:1000, :] # downsample to 500*1000*20 for fast calculation\n",
    "sampled_matrix = rating_matrix_train_addmean[0:500, 0:1000] # downsample to 500*1000 for fast calculation\n",
    "\n",
    "# TRP-TR-ALS\n",
    "projection_size = [20, 20, 10]\n",
    "tr_rank = [2, 2, 2]\n",
    "\n",
    "\n",
    "tensor_p, Q = tensor_projection(sampled_tensor, projection_size, 2,  0)\n",
    "start1 = timeit.default_timer()\n",
    "cores_projection = TR_ALS(tensor_p, tr_rank, maxiter=10)\n",
    "# print('Tensor decomposition completed.')\n",
    "cores1 = tensor_back_projection(cores_projection, Q)\n",
    "tensor1 = cores2tensor_new(cores1)\n",
    "# print('Rating prediction completed.')\n",
    "stop1 = timeit.default_timer()\n",
    "\n",
    "# prediction1 = tensor1 + user_ratings_mean\n",
    "\n",
    "# TRALS\n",
    "start2 = timeit.default_timer()\n",
    "tensor2 = cores2tensor_new(TR_ALS(sampled_tensor, tr_rank, maxiter=10))\n",
    "stop2 = timeit.default_timer()\n",
    "\n",
    "# prediction2 = tensor2 + user_ratings_mean\n",
    "\n",
    "# TR-ALS matrix\n",
    "tr_rank_m = [2, 2]\n",
    "start3 = timeit.default_timer()\n",
    "tensor3 = cores2tensor_new(TR_ALS(sampled_matrix, tr_rank, maxiter=10))\n",
    "stop3 = timeit.default_timer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spend of TRP-TR-ALS is 0.34s, time spend of TR-ALS is 9.12s, time spend of TR-ALS matrix is 0.06s\n",
      "MAE of TRP-TR-ALS is 0.8394, MAE of TR-ALS is 0.8265, MAE of TR-ALS matrix is 0.7590,\n",
      "RMSE of TRP-TR-ALS is 1.0215, RMSE of TR-ALS is 1.0104, RMSE of TR-ALS matrix is 0.9417,\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "sampled_tensor_test = rating_tensor_test[0:500, 0:1000, :]\n",
    "index = np.int64(sampled_tensor_test>0) # a binary tesor marking the exsiting ratings as 1\n",
    "num = index.sum() # number of ratings\n",
    "\n",
    "sampled_matrix_test = rating_matrix_test[0:500, 0:1000]\n",
    "index_m = np.int64(sampled_matrix_test>0) # a binary tesor marking the exsiting ratings as 1\n",
    "\n",
    "\n",
    "prediction_tensor1 = tensor1 * index\n",
    "prediction_tensor2 = tensor2 * index\n",
    "prediction_tensor3 = tensor3 * index_m\n",
    "\n",
    "# Evaluation on test dataset\n",
    "MAE1 = evaluation_MAE(sampled_tensor_test, prediction_tensor1*index)*tensor1.size/num\n",
    "MAE2 = evaluation_MAE(sampled_tensor_test, prediction_tensor2*index)*tensor2.size/num\n",
    "MAE3 = evaluation_MAE(sampled_matrix_test, prediction_tensor3*index_m)*tensor3.size/num\n",
    "\n",
    "RMSE1 = evaluation_RMSE(sampled_tensor_test, prediction_tensor1)*np.sqrt(tensor1.size/num)\n",
    "RMSE2 = evaluation_RMSE(sampled_tensor_test, prediction_tensor2)*np.sqrt(tensor2.size/num)\n",
    "RMSE3 = evaluation_RMSE(sampled_matrix_test, prediction_tensor3)*np.sqrt(tensor3.size/num)\n",
    "\n",
    "\n",
    "print('Time spend of TRP-TR-ALS is %.2fs, time spend of TR-ALS is %.2fs, time spend of TR-ALS matrix is %.2fs' %(stop1 - start1, stop2 - start2, stop3-start3))\n",
    "print('MAE of TRP-TR-ALS is %.4f, MAE of TR-ALS is %.4f, MAE of TR-ALS matrix is %.4f,' %(MAE1, MAE2, MAE3))\n",
    "print('RMSE of TRP-TR-ALS is %.4f, RMSE of TR-ALS is %.4f, RMSE of TR-ALS matrix is %.4f,' %(RMSE1, RMSE2, RMSE3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 0. 1.]\n",
      "0.7032191069574247\n"
     ]
    }
   ],
   "source": [
    "# precision and recall\n",
    "sampled_tensor_rec = sampled_tensor_test.copy()\n",
    "sampled_tensor_rec[sampled_tensor_test>=3.5] = 1\n",
    "sampled_tensor_rec[sampled_tensor_test <3.5 ] = 0\n",
    "sampled_rec_real = sampled_tensor_rec[index!=0]\n",
    "\n",
    "def rating(prediction, user, item):\n",
    "    a = 1\n",
    "    b = 0\n",
    "    rating = prediction[user-1, item-1, :]\n",
    "    if rating.max() >=3.5:\n",
    "        return a\n",
    "    else: \n",
    "        return b\n",
    "tensor1_rec = prediction_tensor1.copy()\n",
    "tensor1_rec[prediction_tensor1>=3.5] = 1\n",
    "tensor1_rec[prediction_tensor1<3.5] = 0\n",
    "sampled_rec_1 = tensor1_rec[index!=0]\n",
    "print(sampled_rec_1)\n",
    "print(sampled_rec_real)\n",
    "num_wrong = np.sum(np.abs(sampled_rec_1 - sampled_rec_real))\n",
    "num_correct = sampled_rec_1.size - num_wrong\n",
    "\n",
    "precision = num_correct/sampled_rec_1.size\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
